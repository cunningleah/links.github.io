---
title: "Collective Intelligence FOO Camp"
date: 2008-02-27 00:04:46 +0000
external-url: http://www.grouplens.org/node/204
hash: 54a2eb071b25a69bcb87f44badc20885
annum:
    year: 2008
    month: 02
hostname: www.grouplens.org
---


I just got back from the Collective Intelligence FOO Camp that O'Reilly organized at Google.  The meeting was great, the people were great, and overall the experience was great. 



One issue that popped up is what exactly people mean by Collective Intelligence.  At a high level, it was clear that everyone meant basically the same thing:



agent -> work
agent -> work
agent -> work                                                                 (some require superlinear)    
agent -> work              ------ combining function  ------> outcome that would
agent -> work                                                                   be harder to produce
agent -> work                                                                   with any individual agent



Interestingly, a number of participants were only interested in examples in which the outcome was superlinear in the number of participants.  I'm not sure why this would be.  Several participants were speculating about what a "complexity theory" of collective intelligence would be like: could we identify problems that are demonstrably more difficult for a collective intelligence to solve than other problems?  



I'm personally more of a "big tent" CI guy.  I think that as long as the result is intelligent, I'm okay with situations in which the individuals agents are providing the real intelligence, and the combining function is simple.  If we want to taxonomize, I can see at least three interesting types of CI: 



 Types of Collective Intelligence



parallel intelligence: many independent agents (e.g., Wikipedia, reCaptcha)
aggregate intelligence: independent agents + combining function that joins the results (e.g., recommender system)
emergent intelligence: the result is intelligent, even if the individuals are not (e.g., ants foraging, leaving scent trails)


Overall, the experience was fun.  I did find it intriguing that we had no tools for applying collective intelligence to the process of creating a "unconference".  For that, we used white boards and markers, lots of sticky notes, and pieces of paper to cover up events that were cancelled.  It would seem easy to do better: people could propose ideas, which would show up on people's laptops. They could say which ones they would like to attend, which would cause them to be scheduled so most people did not have conflicts, and so they would be in rooms of approximately the right size.  If noone wanted to come, they could be cancelled or merged.  It would be fun to see CI in action at a Foo Camp of the future ..



John



 


